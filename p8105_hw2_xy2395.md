p8105\_hw2\_xy2395
================
Jack Yan
9/27/2018

``` r
library(tidyverse)
library(readxl)
library(p8105.datasets)
```

Problem 1
=========

Data Import and Manipulation
----------------------------

``` r
data_nysubway = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(-division, -exit_only, -(staffing:staff_hours), -(ada_notes:entrance_location)) %>% 
  mutate( entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

The code above imported data from the `.csv` file, and cleaned up variable names using `clean_names` function. It also selected variables to be used from the original dataset. Further, it converted the entry variable from character (`YES` vs `NO`) to a logical variable. Now the dataset contains variables of line, station name, station latitude & longitude, routes served, entrance type, entry, vending, and ADA compliance. Now the dataset has 1868 rows (observations) and 19 columns (variables). The data are not yet tidy, because the routes that each station supports are spead along variables from route1 to route11. I will fix this problem in Question 4.

A datailed list of variables in this dataset is shown below:

``` r
names(data_nysubway)
```

    ##  [1] "line"              "station_name"      "station_latitude" 
    ##  [4] "station_longitude" "route1"            "route2"           
    ##  [7] "route3"            "route4"            "route5"           
    ## [10] "route6"            "route7"            "route8"           
    ## [13] "route9"            "route10"           "route11"          
    ## [16] "entrance_type"     "entry"             "vending"          
    ## [19] "ada"

Questions
---------

### Question 1

``` r
data_nysubway = mutate(data_nysubway, station_name_line = paste(station_name, line) )
distinct_station_name_line = distinct(data_nysubway, station_name_line)
nrow(distinct_station_name_line)
```

    ## [1] 465

There are 465 stations.

### Question 2

``` r
data_nysubway %>% 
  filter(ada == TRUE) %>% 
  distinct(station_name_line) %>% 
  nrow()
```

    ## [1] 84

There are 84 ADA compliant stations.

### Question 3

``` r
n_without_vending =
  data_nysubway %>% 
  filter( vending == "NO") %>% 
  nrow()

n_without_vending_allow_entrance = 
  data_nysubway %>% 
  filter( vending == "NO") %>% 
  filter( entry == TRUE) %>% 
  nrow()

n_without_vending_allow_entrance / n_without_vending
```

    ## [1] 0.3770492

The proportion of station entrances / exits without vending allow entrance is 0.38.

### Question 4

Use `gather` to tidy the data so that each value in the previous variables (from `route1` to `route11`) is gathered into a new variable `route_served`. Then filter out rows containing `NA`s in the `route_served` variable and delete the unnecessary `route_number` variable.

``` r
tidy_data_nysubway = 
  gather(data_nysubway, key = route_number, value = route_served, route1:route11) %>% 
  filter(route_served != 'NA') %>% 
  select(-route_number)

tidy_data_nysubway %>% 
  filter(route_served == "A") %>% 
  distinct(station_name_line) %>% 
  nrow()
```

    ## [1] 60

``` r
tidy_data_nysubway %>% 
  filter(route_served == "A") %>% 
  filter(ada == TRUE) %>% 
  distinct(station_name_line) %>% 
  nrow()
```

    ## [1] 17

There are 60 distinct stations serving the A train, and 17 of them are ADA compliant.

Problem 2
=========

Mr. Trash Wheel Dataset
-----------------------

``` r
data_mrtw = 
  read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",range = 'A2:N256') %>% 
  janitor::clean_names() %>% 
  filter(dumpster != "NA") %>% 
  mutate(sports_balls = as.integer(sports_balls))
```

Precipitation Dataset
---------------------

``` r
data_prcpttn_2016 = 
    read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = '2016 Precipitation', range = "A2:B14") %>% 
    janitor::clean_names() %>% 
    filter(total != "NA") %>% 
    mutate(year = 2016)
    
data_prcpttn_2017 = 
    read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = '2017 Precipitation', range = "A2:B14")  %>% 
    janitor::clean_names() %>% 
    filter(total != "NA") %>% 
    mutate(year = 2017)

data_prcpttn = bind_rows(data_prcpttn_2016, data_prcpttn_2017) %>% 
    mutate(month = month.name[month]) %>% 
    select(year, month, total)
```

Interpretation
--------------

There are 215 observations and 14 variables in the Mr. Trash Wheel dataset, and 20 observations and 3 variables in the precipitation dataset. Key variables in the Mr. Trash Wheel dataset include `dumpster`, `weight_tons`, number of different items (such as `sports_balls`) and `homes_powered`. For the precipitation dataset, the key variable is `total` which denotes the volumn of precipitation for each month. The total precipitation in 2017 was 29.93. The median number of sports balls in a dumpster in 2016 was `median(filter(data_mrtw, year == 2016)$sports_balls)`.

Problem 3
=========

Data Import and Cleaning
------------------------

The following code trunk

-   formats the data to use appropriate variable names using `clean_names()`,
-   focuses on the “Overall Health” topic using `filter()`, and
-   excludes variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation using `select()`.

``` r
tidy_brfss = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health")  %>% 
  select(-(class:question), -sample_size, -(confidence_limit_low : geo_location)) 
```

The following code trunk

-   structures data so that responses (excellent to poor) are variables taking the value of `data_value`, using `spread()`,
-   sort the variables from `excellent` to `poor`, and
-   creates a new variable showing the proportion of responses that were “Excellent” or “Very Good”.

``` r
structured_brfss = 
  tidy_brfss %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  select(year, locationabbr, locationdesc, excellent, very_good, good, fair, poor) %>% 
  mutate(excellent_and_very_good = excellent + very_good)
```

Questions
---------

-   There are 404 unique locations included in the dataset.
-   There are 51 distinct locations in the variable `locationabbr`, representing all the 50 states and DC.
-   NJ is observed the most.
-   The median of the “Excellent” response value in 2002 was 23.6.

Code calculating these questions are shown below:

``` r
# How many unique locations are included in the dataset?
distinct(structured_brfss, locationdesc) %>% 
  nrow()
```

    ## [1] 404

``` r
# Is every state represented? 
distinct(structured_brfss, locationabbr) %>% 
  nrow()
```

    ## [1] 51

``` r
# What state is observed the most?
count(structured_brfss, locationabbr) %>% 
  arrange(desc(n)) %>% 
  head(1)
```

    ## # A tibble: 1 x 2
    ##   locationabbr     n
    ##   <chr>        <int>
    ## 1 NJ             146

``` r
# In 2002, what is the median of the “Excellent” response value?
structured_brfss_2002 = filter(structured_brfss, year == 2002) 
median(structured_brfss_2002$excellent, na.rm = T)
```

    ## [1] 23.6

Graphs
------

Make a histogram of “Excellent” response values in the year 2002.

``` r
ggplot(structured_brfss_2002, aes(x = excellent)) + 
  geom_histogram()
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

    ## Warning: Removed 2 rows containing non-finite values (stat_bin).

![](p8105_hw2_xy2395_files/figure-markdown_github/unnamed-chunk-14-1.png)

Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

``` r
structured_brfss_ny = 
  structured_brfss %>% 
  filter(year>=2002, year<=2010) %>% 
  filter(locationdesc == "NY - Queens County" | locationdesc ==  "NY - New York County")

ggplot(structured_brfss_ny, aes(x = year, y = excellent)) + 
  geom_point(aes(color = locationdesc))
```

![](p8105_hw2_xy2395_files/figure-markdown_github/unnamed-chunk-15-1.png)
